{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Hypernyms.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a14c0f6aed254e27853525f2eb60c83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_ded5255f9a8d4be0aa5508e1342c49bf",
            "_dom_classes": [],
            "description": "Draw",
            "_model_name": "ButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_7fb2102f2cca4925a1e6d1d61c87e682",
            "_model_module": "@jupyter-widgets/controls",
            "icon": ""
          }
        },
        "7f4cbdb5163c4150ba2677966d75bfbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_799b4924e776483baca6800dd19ef639",
            "_dom_classes": [],
            "description": "String:",
            "_model_name": "TextModel",
            "placeholder": "Query",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "ДОКУМЕНТ",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9901e00daa85403ab4567fabd51a175b"
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beknur/NLP/blob/master/Hypernyms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5om5MQuALAi5",
        "colab_type": "code",
        "outputId": "6ba338d3-43ce-4b5a-d800-d75a48576504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "pip install wikipedia"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.21.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp36-none-any.whl size=11686 sha256=12488a0a2e90277289c7363fd3180ca83a2972a11ff2d3c5397d52fb51161480\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T17:56:22.948195Z",
          "start_time": "2020-02-12T17:56:22.944176Z"
        },
        "id": "NRjv6TVmIy_F",
        "colab_type": "text"
      },
      "source": [
        "### Lab 2: Hyponyms and Hypernyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:16.470920Z",
          "start_time": "2020-02-12T14:12:15.640262Z"
        },
        "id": "-gBTAQmDIy_J",
        "colab_type": "code",
        "outputId": "47197e0b-a080-4374-a9f4-fc4f30108cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import pandas as pd\n",
        "import wikipedia\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual,widgets\n",
        "from IPython.display import display\n",
        "import json\n",
        "import urllib.request\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import quote\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "print(num_cores)\n",
        "wikipedia.set_lang(\"ru\")\n",
        "# DATA_PATH_LIST = ['D:','src2','taxonomy-enrichment','data','training_data']\n",
        "DATA_PATH_LIST = ['.']\n",
        "EMBEDDING_MODEL_FILENAME = \"wiki_node2vec.bin\"\n",
        "DATA_PATH=\"training_nouns.tsv\"\n",
        "df = pd.read_csv(\"training_nouns.tsv\",sep='\\t')\n",
        "print(df)\n",
        "%matplotlib inline"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "      SYNSET_ID  ...                                       PARENT_TEXTS\n",
            "0      126551-N  ...  ['СОВЕРШЕННОЛЕТНИЕ ЛИЦА, СОВЕРШЕННОЛЕТНИЙ ГРАЖ...\n",
            "1      126551-N  ...  ['ВЕРУЮЩИЙ В ХРИСТА, БРАТЬЯ ВО ХРИСТЕ, ХРИСТИА...\n",
            "2      120440-N  ...  ['ВЫРАЖЕНИЕ ЛИЦА, ВЫРАЖЕНИЕ, МИНА, ВЫРАЖЕНИЕ Н...\n",
            "3      120440-N  ...  ['ПРЕПОДНЕСЕНИЕ, ПРЕДСТАВЛЕНИЕ', 'ОСМЕИВАНИЕ, ...\n",
            "4        1277-N  ...  ['БУХГАЛТЕРСКИЙ ДОКУМЕНТ, ДОКУМЕНТ БУХГАЛТЕРСК...\n",
            "...         ...  ...                                                ...\n",
            "17237  131787-N  ...  ['НЕДОМОГАНИЕ, ЗАБОЛЕВАНИЕ ЧЕЛОВЕКА, ЗАБОЛЕВАН...\n",
            "17238  142357-N  ...  ['НЕДОМОГАНИЕ, ЗАБОЛЕВАНИЕ ЧЕЛОВЕКА, ЗАБОЛЕВАН...\n",
            "17239  144031-N  ...  ['НЕДОМОГАНИЕ, ЗАБОЛЕВАНИЕ ЧЕЛОВЕКА, ЗАБОЛЕВАН...\n",
            "17240  147153-N  ...  ['НЕДОМОГАНИЕ, ЗАБОЛЕВАНИЕ ЧЕЛОВЕКА, ЗАБОЛЕВАН...\n",
            "17241  153553-N  ...  ['НЕДОМОГАНИЕ, ЗАБОЛЕВАНИЕ ЧЕЛОВЕКА, ЗАБОЛЕВАН...\n",
            "\n",
            "[17242 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:16.475780Z",
          "start_time": "2020-02-12T14:12:16.473114Z"
        },
        "id": "e5bu7YRcIy_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prestr(x):\n",
        "    return str(x).replace('\\\"','').replace(\"'\",'\"')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:16.685506Z",
          "start_time": "2020-02-12T14:12:16.477634Z"
        },
        "id": "ugnVRLB_Iy_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DefDict(defaultdict):\n",
        "    def __missing__(self, key):\n",
        "        self[key] = key\n",
        "        return key\n",
        "    \n",
        "idx2syns = DefDict(lambda x:x)\n",
        "for val in df.values:\n",
        "    idx2syns[val[0]]=val[1]\n",
        "    try:\n",
        "        pidxs = json.loads(prestr(val[2]))\n",
        "        concp = [el.split(\",\")[0] for el in json.loads(prestr(val[3]))]\n",
        "        idx2syns.update(dict(zip(pidxs,concp)))\n",
        "    except:\n",
        "        print(prestr(val[2]))\n",
        "        print(prestr(val[3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T17:12:34.060220Z",
          "start_time": "2020-02-12T17:12:34.055235Z"
        },
        "id": "cE3nEtUgIy_U",
        "colab_type": "text"
      },
      "source": [
        "### Interactive visualization of hyponyms and hypernyms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkmML02-Uqp0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PMP81ifQUJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "f56a8dc9-3f52-47c8-83a8-509d61c09c0e"
      },
      "source": [
        "!apt-get -qq install -y graphviz libgraphviz-dev graphviz-dev pkg-config"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libgtk2.0-common.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 134443 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../1-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../2-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../3-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libxdot4.\n",
            "Preparing to unpack .../4-libxdot4_2.40.1-2_amd64.deb ...\n",
            "Unpacking libxdot4 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvc6-plugins-gtk.\n",
            "Preparing to unpack .../5-libgvc6-plugins-gtk_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvc6-plugins-gtk (2.40.1-2) ...\n",
            "Selecting previously unselected package libgraphviz-dev.\n",
            "Preparing to unpack .../6-libgraphviz-dev_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgraphviz-dev (2.40.1-2) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../7-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up libxdot4 (2.40.1-2) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgvc6-plugins-gtk (2.40.1-2) ...\n",
            "Setting up libgraphviz-dev (2.40.1-2) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aw991Stdz8V",
        "colab_type": "code",
        "outputId": "36b408f6-2ec4-4f17-e8c3-64b555cd2520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "pip install pygraphviz"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygraphviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/b1/d6d849ddaf6f11036f9980d433f383d4c13d1ebcfc3cd09bc845bda7e433/pygraphviz-1.5.zip (117kB)\n",
            "\r\u001b[K     |██▉                             | 10kB 23.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 4.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pygraphviz\n",
            "  Building wheel for pygraphviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygraphviz: filename=pygraphviz-1.5-cp36-cp36m-linux_x86_64.whl size=157577 sha256=74183a249a4c82c453bddf4472c8c07f6654bc362a324af9b968ec3a4b932c33\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/54/69/1aee9e66ab19916293208d4c9de0d3898adebe6b2eeff6476b\n",
            "Successfully built pygraphviz\n",
            "Installing collected packages: pygraphviz\n",
            "Successfully installed pygraphviz-1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T17:11:37.966489Z",
          "start_time": "2020-02-12T17:11:37.931688Z"
        },
        "id": "AWv4lTaEIy_V",
        "colab_type": "code",
        "outputId": "68b1fd33-12f3-4f8f-edcf-a4c01b574871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "a14c0f6aed254e27853525f2eb60c83a",
            "7f4cbdb5163c4150ba2677966d75bfbc"
          ]
        }
      },
      "source": [
        "button = widgets.Button(description=\"Draw\")\n",
        "query = widgets.Text(\n",
        "    value='ДОКУМЕНТ',\n",
        "    placeholder='Query',\n",
        "    description='String:',\n",
        "    disabled=False\n",
        ")\n",
        "display(button,query)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def creategraph(df):\n",
        "    res = []\n",
        "    for row in df.values:\n",
        "        cohyps = row[1].split(\",\")\n",
        "        for idx,cohyp in enumerate(cohyps):\n",
        "            for parent in json.loads(prestr(row[2])):\n",
        "                res.append((row[0]+'-'+str(idx),parent))\n",
        "    return res\n",
        "\n",
        "def graphdraw(b):\n",
        "    print(\"graphdraw\",query.value)\n",
        "    subset = df[df['TEXT'].str.contains(query.value.upper())]\n",
        "    g = nx.DiGraph()\n",
        "    for el in subset.values:\n",
        "        cohyps = el[1].split(\",\")\n",
        "        print(cohyps)\n",
        "        syns = idx2syns[el[0]]\n",
        "        for child in cohyps:\n",
        "            for parent in json.loads(prestr(el[2])):\n",
        "                ed = g.add_edge(child,idx2syns[parent],label=\"is a\")\n",
        "    plt.figure(figsize=(15,15))\n",
        "    pos = nx.nx_agraph.graphviz_layout(g)\n",
        "    nx.draw(g,with_labels=True,pos=pos)\n",
        "#     edge_labels=nx.draw_networkx_edge_labels(g,pos=pos)\n",
        "    plt.show()\n",
        "button.on_click(graphdraw)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a14c0f6aed254e27853525f2eb60c83a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Button(description='Draw', style=ButtonStyle())"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f4cbdb5163c4150ba2677966d75bfbc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Text(value='ДОКУМЕНТ', description='String:', placeholder='Query')"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T11:38:20.619158Z",
          "start_time": "2020-02-12T11:38:20.614734Z"
        },
        "id": "R5Q5BNPsIy_Z",
        "colab_type": "text"
      },
      "source": [
        "### Pattern extractor\n",
        "\n",
        "Yargy — библиотека для извлечения структурированной информации из текстов на русском языке. Правила описываются контекстно-свободными грамматиками и словарями ключевых слов. Банк готовых правил для имён, дат, адресов и других сущностей доступен в репозитории Natasha.\n",
        "* https://yargy.readthedocs.io/ru/latest/\n",
        "* http://pymorphy2.readthedocs.io/en/latest/user/grammemes.html\n",
        "* https://github.com/natasha/natasha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-02-12T13:09:50.486Z"
        },
        "id": "NZJDJWRbIy_a",
        "colab_type": "text"
      },
      "source": [
        "### Токенизатор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrxEB-Z1Zdpv",
        "colab_type": "code",
        "outputId": "19e147ec-4c30-4cd5-e167-490e71f83b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "pip install yargy"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yargy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/64/d6abf637228bed6b0249b522f588d19dca9f09ab65db13bef41096f51889/yargy-0.12.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.4MB/s \n",
            "\u001b[?25hCollecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hCollecting backports.functools-lru-cache==1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/40/0b1db94fdfd71353ae67ec444ff28e0a7ecc25212d1cb94c291b6cd226f9/backports.functools_lru_cache-1.3-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 15.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->yargy) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2, backports.functools-lru-cache, yargy\n",
            "Successfully installed backports.functools-lru-cache-1.3 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 yargy-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:16.819980Z",
          "start_time": "2020-02-12T14:12:16.708109Z"
        },
        "id": "aRcR3KC0Iy_b",
        "colab_type": "code",
        "outputId": "51d756eb-99ba-471a-a4dd-37d9c58c9c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from yargy.tokenizer import MorphTokenizer\n",
        "\n",
        "\n",
        "tokenizer = MorphTokenizer()\n",
        "text = '''Ростов-на-Дону\n",
        "Длительностью 18ч. 10мин.\n",
        "Яндекс.Такси\n",
        "π ≈ 3.1415\n",
        "1 500 000$\n",
        "http://vk.com\n",
        "'''\n",
        "for line in text.splitlines():\n",
        "    print([_.value for _ in tokenizer(line)])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ростов', '-', 'на', '-', 'Дону']\n",
            "['Длительностью', '18', 'ч', '.', '10', 'мин', '.']\n",
            "['Яндекс', '.', 'Такси']\n",
            "['π', '≈', '3', '.', '1415']\n",
            "['1', '500', '000', '$']\n",
            "['http', ':', '/', '/', 'vk', '.', 'com']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T13:11:56.582467Z",
          "start_time": "2020-02-12T13:11:56.566175Z"
        },
        "id": "eD-Y3_8uIy_g",
        "colab_type": "text"
      },
      "source": [
        "# Газеттир\n",
        "Газеттир нужен для удобной работы с последовательностью слов. Например, можно написать:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:16.844412Z",
          "start_time": "2020-02-12T14:12:16.821582Z"
        },
        "id": "49GPlcsYIy_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from yargy import or_, rule\n",
        "from yargy.predicates import normalized\n",
        "\n",
        "RULE = or_(\n",
        "    rule(normalized('dvd'), '-', normalized('диск')),\n",
        "    rule(normalized('видео'), normalized('файл'))\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:16.968622Z",
          "start_time": "2020-02-12T14:12:16.846737Z"
        },
        "id": "Dd_3HK_LIy_j",
        "colab_type": "code",
        "outputId": "572020c7-84a2-466f-96a8-c1515025933e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from yargy import Parser\n",
        "from yargy.pipelines import morph_pipeline\n",
        "\n",
        "\n",
        "RULE = morph_pipeline([\n",
        "    'dvd-диск',\n",
        "    'видео файл',\n",
        "    'видеофильм',\n",
        "    'газета',\n",
        "    'электронный дневник',\n",
        "    'эссе',\n",
        "])\n",
        "\n",
        "parser = Parser(RULE)\n",
        "text = 'Видео файл на dvd-диске'\n",
        "for match in parser.findall(text):\n",
        "    print([_.value for _ in match.tokens])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Видео', 'файл']\n",
            "['dvd', '-', 'диске']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:54.576104Z",
          "start_time": "2020-02-12T14:12:54.511149Z"
        },
        "id": "ePoc2vdfIy_m",
        "colab_type": "code",
        "outputId": "8e10e90f-ca0b-441c-a39b-39ff684d0dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from yargy import Parser, rule, and_\n",
        "from yargy.predicates import gram, is_capitalized, dictionary\n",
        "\n",
        "\n",
        "GEO = rule(\n",
        "    and_(\n",
        "        gram('ADJF'),  # так помечается прилагательное, остальные пометки описаны в\n",
        "                       # http://pymorphy2.readthedocs.io/en/latest/user/grammemes.html\n",
        "        is_capitalized()\n",
        "    ),\n",
        "    gram('ADJF').optional().repeatable(),\n",
        "    dictionary({\n",
        "        'федерация',\n",
        "        'республика'\n",
        "    })\n",
        ")\n",
        "\n",
        "\n",
        "parser = Parser(GEO)\n",
        "text = '''\n",
        "В Чеченской республике на день рождения ...\n",
        "Донецкая народная республика провозгласила ...\n",
        "Башня Федерация — одна из самых высоких ...\n",
        "'''\n",
        "for match in parser.findall(text):\n",
        "    print([_.value for _ in match.tokens])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Чеченской', 'республике']\n",
            "['Донецкая', 'народная', 'республика']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T13:13:57.167613Z",
          "start_time": "2020-02-12T13:13:57.159920Z"
        },
        "id": "1zWGYIlOIy_p",
        "colab_type": "text"
      },
      "source": [
        "### Предикаты\n",
        "\n",
        "Предикат — функция, которая принимает на вход токен и возвращает True или False. В Yargy встроено много готовых предикатов. Полный список есть в справочнике. Предикаты комбинируются с помощью and_, or_ и not_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:17.173350Z",
          "start_time": "2020-02-12T14:12:17.136108Z"
        },
        "id": "xLa3OILDIy_q",
        "colab_type": "code",
        "outputId": "3768db46-e1f2-43e7-e443-7b8a8cd45939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from yargy import and_, not_\n",
        "from yargy.tokenizer import MorphTokenizer\n",
        "from yargy.predicates import is_capitalized, eq\n",
        "\n",
        "\n",
        "tokenizer = MorphTokenizer()\n",
        "token = next(tokenizer('Стали'))\n",
        "\n",
        "predicate = is_capitalized()\n",
        "print(predicate(token))\n",
        "\n",
        "predicate = and_(\n",
        "    is_capitalized(),\n",
        "    not_(eq('марки'))\n",
        ")\n",
        "print(predicate(token))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T13:15:56.600763Z",
          "start_time": "2020-02-12T13:15:56.596609Z"
        },
        "id": "RB1Xb_KRIy_t",
        "colab_type": "text"
      },
      "source": [
        "### Грамматики\n",
        "В Yargy используется специальный DSL для описания грамматик. Любую контекстно-свободную грамматику можно описать с помощью конструкций Питона. Например, есть примитивная грамматика для размеров одежды:\n",
        "\n",
        "KEY -> р. | размер\n",
        "\n",
        "VALUE -> S | M | L\n",
        "\n",
        "SIZE -> KEY VALUE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:14:21.602988Z",
          "start_time": "2020-02-12T14:14:21.589310Z"
        },
        "id": "ctFMEWVLIy_u",
        "colab_type": "code",
        "outputId": "492a2d88-1788-4978-8093-94737df95529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from yargy import rule, or_\n",
        "\n",
        "\n",
        "KEY = or_(\n",
        "    rule('р', '.'),\n",
        "    rule('размер')\n",
        ").named('KEY')\n",
        "VALUE = or_(\n",
        "    rule('S'),\n",
        "    rule('M'),\n",
        "    rule('L'),\n",
        "    rule('XS'),\n",
        ").named('VALUE')\n",
        "SIZE = rule(\n",
        "    KEY,\n",
        "    VALUE\n",
        ").named('SIZE')\n",
        "SIZE.normalized.as_bnf"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SIZE -> KEY VALUE\n",
              "KEY -> 'р' '.' | 'размер'\n",
              "VALUE -> 'S' | 'M' | 'L' | 'XS'\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:14:27.723857Z",
          "start_time": "2020-02-12T14:14:27.662113Z"
        },
        "id": "e367SV-rIy_w",
        "colab_type": "code",
        "outputId": "54315a77-b919-4248-f4ba-79fdb59219c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "parser = Parser(\n",
        "    SIZE\n",
        ")\n",
        "text = 'размер M; размер A; размер XS;'\n",
        "for match in parser.findall(text):\n",
        "    print([_.value for _ in match.tokens])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['размер', 'M']\n",
            "['размер', 'XS']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:19.308726Z",
          "start_time": "2020-02-12T14:12:17.354354Z"
        },
        "id": "Tmj9CFgmIy_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from yargy import Parser, rule, and_, or_, not_\n",
        "from yargy.interpretation import fact, attribute\n",
        "from yargy.predicates import gram, is_capitalized, dictionary, eq\n",
        "import re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook\n",
        "from gensim import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:19.323139Z",
          "start_time": "2020-02-12T14:12:19.310769Z"
        },
        "id": "uQpKFXmoIy_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "START = rule(\n",
        "    or_(\n",
        "        rule(gram('ADJF')),\n",
        "        rule(gram('NOUN'))\n",
        "    ).optional(),\n",
        "    gram('NOUN')\n",
        ")\n",
        "\n",
        "START_S = or_(\n",
        "    eq('такой'),\n",
        "    eq('такие'),\n",
        ")\n",
        "\n",
        "KAK = eq('как')\n",
        "INCLUDING = or_(\n",
        "    or_(\n",
        "        eq('в'),\n",
        "        eq('том'),\n",
        "        eq('числе'),\n",
        "    ),\n",
        "    eq('включающий'),\n",
        "    or_(\n",
        "        eq('включающий'),\n",
        "        eq('в'),\n",
        "        eq('себя'),\n",
        "    ),\n",
        "    or_(\n",
        "        eq('включающие'),\n",
        "        eq('в'),\n",
        "        eq('себя'),\n",
        "    ),\n",
        "    eq('включающие'),\n",
        "    eq('особенно'),\n",
        "\n",
        ")\n",
        "\n",
        "MID_S = or_(\n",
        "    rule(\n",
        "        or_(\n",
        "            eq('такой'),\n",
        "            eq('такие'),\n",
        "        ),\n",
        "        eq('как')\n",
        "    )\n",
        ")\n",
        "ATAKJE = rule(\n",
        "    eq(','),\n",
        "    eq('а'),\n",
        "    eq('также')\n",
        ")\n",
        "\n",
        "MID = or_(\n",
        "    rule(\n",
        "        eq('это')\n",
        "    ),\n",
        "    rule(\n",
        "        eq('—')\n",
        "    ),\n",
        "    rule(\n",
        "        eq('—'),\n",
        "        eq('это')\n",
        "    ),\n",
        "    rule(\n",
        "        eq('—'),\n",
        "        not_(eq('км'))\n",
        "    ),\n",
        "    rule(\n",
        "        or_(\n",
        "            eq('и'),\n",
        "            eq('или'),\n",
        "        ),\n",
        "        eq('другие')\n",
        "    )\n",
        ")\n",
        "\n",
        "END = or_(\n",
        "    rule(\n",
        "        gram('NOUN'),\n",
        "        gram('NOUN')\n",
        "    ),\n",
        "    rule(\n",
        "        gram('ADJF').repeatable(),\n",
        "        gram('NOUN')\n",
        "    ),\n",
        "    rule(\n",
        "        gram('ADJF'),\n",
        "        gram('ADJF').repeatable(),\n",
        "        gram('NOUN')\n",
        "    ),\n",
        "    rule(\n",
        "        gram('NOUN').repeatable(),\n",
        "        gram('ADJF'),\n",
        "        gram('NOUN').repeatable()\n",
        "    ),\n",
        "    rule(\n",
        "        gram('NOUN').repeatable()\n",
        "    )\n",
        ")\n",
        "\n",
        "Item = fact(\n",
        "    'Item',\n",
        "    [attribute('titles').repeatable()]\n",
        ")\n",
        "\n",
        "\n",
        "IGNORE = rule(\n",
        "    '(',\n",
        "    not_(eq(')')).repeatable(),\n",
        "    ')'\n",
        ")\n",
        "\n",
        "ITEM = rule(\n",
        "    IGNORE.interpretation(\n",
        "        Item.titles\n",
        "    ),\n",
        "    eq(',').optional() \n",
        ").repeatable().interpretation(\n",
        "    Item\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:19.434702Z",
          "start_time": "2020-02-12T14:12:19.324707Z"
        },
        "id": "aXLYyr2aIy_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_hyperonyms(main_word):\n",
        "    HYPONYM = eq(utils.deaccent(main_word))\n",
        "    RULE = or_(\n",
        "        rule(HYPONYM, ATAKJE, START, MID, END),\n",
        "        rule(HYPONYM, MID, END),\n",
        "        rule(START_S, END, KAK, HYPONYM),\n",
        "        rule(END, INCLUDING, HYPONYM)\n",
        "    )\n",
        "    parser = Parser(RULE) \n",
        "    text = utils.deaccent(wikipedia.summary(main_word))\n",
        "    print(text)\n",
        "    text = re.sub(r'\\(.+?\\)', '', text)\n",
        "    text = text.lower().replace('* сергии радонежскии* ', '')\n",
        "    for idx, match in enumerate(parser.findall(text.lower())):\n",
        "        k = [_.value for _ in match.tokens]\n",
        "        print(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-12T14:12:22.648500Z",
          "start_time": "2020-02-12T14:12:19.437840Z"
        },
        "id": "oZdd5tJKIy__",
        "colab_type": "code",
        "outputId": "6f2f530c-033b-454d-ea9e-c7b8d28e7b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "get_hyperonyms(\"АБСЕНТЕИЗМ\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Абсентеизм (от лат. absens, absentis — отсутствующии, англ. absenteeism) — уклонение избирателеи от участия в голосовании на выборах, или, в более широком понимании, политическое поведение, характеризующееся бездеиствием, то есть уклонением от какого-либо политического участия (электоральное поведение, партииная деятельность, участие в митингах и демонстрациях и т. д.), но главным образом подразумевается уклонение от своих прямых электоральных функции.\n",
            "Также абсентеизмом называют поведенческую модель, при которои работник систематически отсутствует на рабочем месте и избегает своих обязанностеи. Традиционно абсентеизм рассматривается как индикатор плохои индивидуальнои производительности и как одна из главных проблем менеджмента, исследование которои развивается в экономических и квази-экономических терминах. Последние исследования в этои области сосредоточились на рассмотрении и осмыслении абсентеизма в роли индикатора психологическои, медицинскои и социальнои адаптации к работе.\n",
            "Наиболее видная психологическая модель «ухода» (withdrawal model) предполагает, что абсентеизм представляет собои реакцию индивида на неудовлетворительные рабочие условия. Данная модель находит эмпирические подтверждения отрицательнои связи между отсутствием на рабочем месте и общеи удовлетворенностью работои. Более того, данная теория находит подтверждение «прогресса ухода», начиная с невинных опоздании до прогулов работы и заканчивая увольнениями. Психологические исследования также указывают на предрасположенность сотрудников к абсентеизму.\n",
            "Мерои абсентеизма чаще всего выступает общее количество пропущенных днеи (или часов) или частота отсутствия\n",
            "сотрудника на работе. Стоит отметить, что учитываются пропуски как по уважительнои, так и по неуважительнои причине.\n",
            "Абсентеизм, наряду с текучкои кадров, рассматривается как реакция сотрудников на условия труда, и является одним из главных показателеи эффективности работы с персоналом, которая направлена на создание успешного личностно-организационного соответствия.\n",
            "Абсентеизм, являясь однои из самых распространенных причин увольнения сотрудников, наносит серьезныи экономическии ущерб предприятиям.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmoZNP0NIzAC",
        "colab_type": "text"
      },
      "source": [
        "#### Task 1 (deadline 19.02.2020 24:00)\n",
        "* Find your name on the spreadsheet https://docs.google.com/spreadsheets/d/1RR2I6toCkebbGU1UK83HS70Ru_l0_o-nnZIHyiFB0No/edit?usp=sharing. In opposite of your name there are 24 words of hyponyms, you have to insert five corresponding hypernyms next to them. Examples of hyponyms and hyperonyms relationship you can find above in the current Jupiter notebook.\n",
        "* Find for each pair of hyponyms and hypernyms a corresponding snippet of a text with their mentions. The source of the text can be any free resources, e.g., Wikipedia, Google, Yandex, others. You should save the snippets and their URLs within the lab2 folder in your NLP git-repo with .csv file-extension in a single file.\n",
        "\n",
        "#### Task 2 (deadline 26.02.2020 24:00)\n",
        "* It would be best if you created a pandas DataFrame of the texts from the previous task. And apply to the DataFrame the function 'get_hyperonyms,' which must return the list of the corresponding hypernyms from the text automatically. If there are errors or misses, you should fix them in the code for your case of the 24 words. Nevertheless, it is strictly prohibited to use hard coding. Save your notebook with parser code within the lab2 folder in your NLP git-repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHlQcW1rBrot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "69d3c69c-e142-4510-f37c-9133e2d603ab"
      },
      "source": [
        "words = pd.read_excel('wordsNLPLab2.xlsx', sep='|', encoding='utf-8')\n",
        "\n",
        "words.head()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HYPONYM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ПРЕСЕРВЫ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ПРЕССОВЩИК</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ПРЕФЕРАНС</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ПРИБОРИСТ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ПРИВОДНЕНИЕ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       HYPONYM\n",
              "0     ПРЕСЕРВЫ\n",
              "1   ПРЕССОВЩИК\n",
              "2    ПРЕФЕРАНС\n",
              "3    ПРИБОРИСТ\n",
              "4  ПРИВОДНЕНИЕ"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyiacyVOBgdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "d0139d87-d0c4-41d3-a6f3-84c8ca271608"
      },
      "source": [
        "wiki = \"https://ru.wiktionary.org/wiki/\"\n",
        "for word in list(words['HYPONYM']):\n",
        "    wordConvert = quote(word.lower(),safe='')\n",
        "    url = wiki + wordConvert\n",
        "    print(\"Слово: \" + word + \" Cсылка: \" + url)\n",
        "    source = urllib.request.urlopen(url).read()\n",
        "    soup = BeautifulSoup(source)\n",
        "    span = soup.select_one(\"#Гиперонимы\")\n",
        "    h4 = span.find_parent('h4')\n",
        "    ol = h4.find_next_sibling('ol')\n",
        "    hyponyms = word + \" => Гиперонимы => \"\n",
        "    for li in ol.find_all('li'):\n",
        "      try:\n",
        "        if li.text:\n",
        "          hyponyms  += li.text.upper() + \", \"\n",
        "      except: \n",
        "        pass\n",
        "    print(hyponyms.replace(\",\",\";\"))\n",
        "    time.sleep(3.0)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово: ПРЕСЕРВЫ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B5%D1%81%D0%B5%D1%80%D0%B2%D1%8B\n",
            "ПРЕСЕРВЫ => Гиперонимы => \n",
            "Слово: ПРЕССОВЩИК Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B5%D1%81%D1%81%D0%BE%D0%B2%D1%89%D0%B8%D0%BA\n",
            "ПРЕССОВЩИК => Гиперонимы => \n",
            "Слово: ПРЕФЕРАНС Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B5%D1%84%D0%B5%D1%80%D0%B0%D0%BD%D1%81\n",
            "ПРЕФЕРАНС => Гиперонимы => КАРТОЧНАЯ ИГРА; ИГРА; —; \n",
            "Слово: ПРИБОРИСТ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D0%B1%D0%BE%D1%80%D0%B8%D1%81%D1%82\n",
            "ПРИБОРИСТ => Гиперонимы => \n",
            "Слово: ПРИВОДНЕНИЕ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D0%B2%D0%BE%D0%B4%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5\n",
            "ПРИВОДНЕНИЕ => Гиперонимы => \n",
            "Слово: ПРИКЛАДНИК Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D0%BA%D0%BB%D0%B0%D0%B4%D0%BD%D0%B8%D0%BA\n",
            "ПРИКЛАДНИК => Гиперонимы => \n",
            "Слово: ПРИКУРИВАТЕЛЬ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D0%BA%D1%83%D1%80%D0%B8%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C\n",
            "ПРИКУРИВАТЕЛЬ => Гиперонимы => \n",
            "Слово: ПРИЛЕЖАНИЕ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D0%BB%D0%B5%D0%B6%D0%B0%D0%BD%D0%B8%D0%B5\n",
            "ПРИЛЕЖАНИЕ => Гиперонимы => \n",
            "Слово: ПРИМАТОЛОГИЯ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D0%BC%D0%B0%D1%82%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F\n",
            "ПРИМАТОЛОГИЯ => Гиперонимы => \n",
            "Слово: ПРИМЕРЗАНИЕ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D0%BC%D0%B5%D1%80%D0%B7%D0%B0%D0%BD%D0%B8%D0%B5\n",
            "ПРИМЕРЗАНИЕ => Гиперонимы => \n",
            "Слово: ПРИНЦИПАЛ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D0%BD%D1%86%D0%B8%D0%BF%D0%B0%D0%BB\n",
            "ПРИНЦИПАЛ => Гиперонимы => \n",
            "Слово: ПРИОН Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D0%BE%D0%BD\n",
            "ПРИОН => Гиперонимы => БЕЛОК; СИАЛОГЛИКОПРОТЕИН; ВОЗБУДИТЕЛЬ; \n",
            "Слово: ПРИПОЙ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D0%BF%D0%BE%D0%B9\n",
            "ПРИПОЙ => Гиперонимы => \n",
            "Слово: ПРИРОДОВЕДЕНИЕ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D1%80%D0%BE%D0%B4%D0%BE%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5\n",
            "ПРИРОДОВЕДЕНИЕ => Гиперонимы => \n",
            "Слово: ПРИТРАВКА Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D1%82%D1%80%D0%B0%D0%B2%D0%BA%D0%B0\n",
            "ПРИТРАВКА => Гиперонимы => \n",
            "Слово: ПРИЧИНИТЕЛЬ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%B8%D1%87%D0%B8%D0%BD%D0%B8%D1%82%D0%B5%D0%BB%D1%8C\n",
            "ПРИЧИНИТЕЛЬ => Гиперонимы => \n",
            "Слово: ПРОБИОТИК Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%BE%D0%B1%D0%B8%D0%BE%D1%82%D0%B8%D0%BA\n",
            "ПРОБИОТИК => Гиперонимы => ПРОДУКТ; БАД; СУБСТАНЦИЯ; \n",
            "Слово: ПРОБНИК Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%BE%D0%B1%D0%BD%D0%B8%D0%BA\n",
            "ПРОБНИК => Гиперонимы => ИЗДЕЛИЕ; ПРИБОР; САМЕЦ; ЭКЗАМЕН; \n",
            "Слово: ПРОВАРКА Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%BE%D0%B2%D0%B0%D1%80%D0%BA%D0%B0\n",
            "ПРОВАРКА => Гиперонимы => \n",
            "Слово: ПРОЖАРКА Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%BE%D0%B6%D0%B0%D1%80%D0%BA%D0%B0\n",
            "ПРОЖАРКА => Гиперонимы => \n",
            "Слово: ПРОКТОЛОГ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%BE%D0%BA%D1%82%D0%BE%D0%BB%D0%BE%D0%B3\n",
            "ПРОКТОЛОГ => Гиперонимы => ВРАЧ; ДОКТОР; МЕДИК; \n",
            "Слово: ПРОКТОЛОГИЯ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%BE%D0%BA%D1%82%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F\n",
            "ПРОКТОЛОГИЯ => Гиперонимы => \n",
            "Слово: ПРОМОАКЦИЯ Cсылка: https://ru.wiktionary.org/wiki/%D0%BF%D1%80%D0%BE%D0%BC%D0%BE%D0%B0%D0%BA%D1%86%D0%B8%D1%8F\n",
            "ПРОМОАКЦИЯ => Гиперонимы => АКЦИЯ; \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsKKcTjL3ld4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43ffe5f8-efd2-4d15-d850-ce716f37a8a7"
      },
      "source": [
        "for word in list(words['HYPONYM']):\n",
        "    print(word)\n",
        "    get_hyperonyms(word)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ПРЕСЕРВЫ\n",
            "Пресервы (от позднелат. praeservo «предохраняю») — рыбные продукты, которые были подвергнуты специальнои обработке (консервации) и упаковке с целью длительного хранения без порчи. Способом консервации является соление — обработка рыбы большим количествам повареннои соли. Кроме этого пресервы обычно содержат антисептик как дополнительныи консервант. \n",
            "В процессе посола происходит некоторая ферментация рыбы — рыба «созревает», в результате чего вкус ее значительно меняется, она становится вкуснее.\n",
            "Пресервы принципиально отличаются от консервов тем, что не проходят тепловои обработки (термическои стерилизации). В связи с этим пресервы требуют строгого соблюдения непрерывности холодильнои цепи с момента изготовления до их потребления. Обычно, температура хранения пресервов составляет от 0 до −8 °C. При этои температуре бактериальные процессы сильно замедляются, но замораживания продукта не происходит (из-за высокого содержания соли). Срок хранения пресервов, в сравнении с консервами, гораздо меньше, обычно — до 4 мес.\n",
            "Сырьем для пресервов являются различные промысловые рыбы — сельдевые, анчоусовые, скумбриевые, ставридовые, лососевые. Наибольшеи популярностью пользуются пресервы из сельди атлантическои и тихоокеанскои, моивы, кильки и иваси. Для производства используют как рыбу-сырец, так и охлажденную, а также мороженую. Ассортимент рыбных пресервов очень широк, выпускаются с рыбои в целом виде, разделаннои на филе, филе-кусочки и тушки.\n",
            "В качестве антисептика применяют бензоинокислыи натрии, а также более безвредныи консервант сорбат калия или уксусную кислоту. В качестве тары для пресервов используется жестяная тара емкостью 50−5000 г, стеклянные банки с жестяными крышками емкостью 50−500 г, банки из полимерных материалов. Жестяная тара для пресервов лакируется изнутри во избежание реакции с агрессивными средами рассолов или маринадов.\n",
            "В СССР в 1980-е годы выпускалось около 100 наименовании различных пресервов, считавшихся высококачественнои деликатеснои продукциеи. Пресервы обычно подаются к столу в качестве закуски.\n",
            "ПРЕССОВЩИК\n",
            "Металлург — профессия людеи, которые занимаются добычеи и переработкои металлов.\n",
            "ПРЕФЕРАНС\n",
            "Преферанс (фр. preference — предпочтение, преимущество) — карточная игра со взятками. Получила распространение в России в середине XIX века. Предшественником преферанса считается вист. Игра ведется втроем или вчетвером (в последнем случае каждыи игрок по очереди пропускает раздачу, что называется «сидит на прикупе») или вдвоем (тогда игру называют «гусарик»). Возможно играть и больше, чем вчетвером, но тогда игра теряет динамичность и интерес к неи снижается, так как карты раздаются только троим участникам, и поэтому каждыи игрок вынужден пропускать две и более раздач подряд.\n",
            "Преферанс является коммерческои игрои, то есть такои игрои на деньги, в которои при длительнои игре результат в большеи степени определяется умением игрока, нежели везением, в отличие от азартных игр. В преферансе деньги не являются элементом стратегии, что делает их необязательнои частью собственно игры.\n",
            "ПРИБОРИСТ\n",
            "Слесарь по контрольно-измерительным приборам и автоматике — профессия рабочего, которыи обслуживает, ремонтирует и эксплуатирует различное контрольно-измерительное оборудование и системы автоматического управления.\n",
            "\n",
            "К работе слесарем по контрольно-измерительным приборам и автоматике допускаются лица не моложе 18 лет, имеющие среднее профессиональное образование или профессиональное обучение, прошедшие медицинское освидетельствование и не имеющие противопоказании к выполнению даннои работы, обучение правилам техники безопасности, профессионально-техническую подготовку, проверку знании по правилам эксплуатации электроустановок потребителеи (ПЭЭП), аттестацию по правилам, нормам и инструкциям по промышленнои безопасности в аттестационнои комиссии. Аттестация слесаря по КИПиА проводится один раз в год. Повторныи инструктаж проводится через 6 месяцев.\n",
            "Слесарь по контрольно-измерительным приборам и автоматике административно подчиняется начальнику цеха, оперативно и технически — мастеру КИПиА цеха или лицу, его замещающему.Дежурныи слесарь по КИПиА оперативно подчиняется мастеру производственного участка (МПУ) , выполняет пусконаладочные работы строго в соответствии с инструкциеи к подключаемому и обслуживаемому в дальнеишем оборудованию (контроллеры, щиты управления). В случае аварииного состояния в цехе дежурныи слесарь по КИПиА деиствует в соответствии с распоряжением МПУ. Во время работы поддерживает связь с оперативным технологическим персоналом. О замеченных неисправностях обязан поставить в известность МПУ.\n",
            "ПРИВОДНЕНИЕ\n",
            "Аварииная посадка A320 на Гудзон — авиационное происшествие, произошедшее 15 января 2009 года. Авиалаинер Airbus A320-214 авиакомпании US Airways выполнял плановыи реис AWE 1549 (позывнои — Cactus 1549) по маршруту Нью-Иорк — Шарлотт — Сиэтл, но всего через 1,5 минуты после взлета столкнулся со стаеи канадских казарок, и у него отказали оба двигателя. Экипаж благополучно посадил самолет на воду реки Гудзон в Нью-Иорке. Все находившиеся на его борту 155 человек (150 пассажиров и 5 членов экипажа) выжили, 83 человека получили ранения — 5 серьезные (больше всех пострадала одна стюардесса) и 78 незначительные.\n",
            "В СМИ происшествие известно как Чудо на Гудзоне (англ. Miracle on the Hudson).\n",
            "По количеству людеи на борту реис 1549 занимает первое место в истории приводнении, обошедшихся без жертв, и второе в истории известных приводнении (после реиса Ethiopian Airlines-961).\n",
            "ПРИКЛАДНИК\n",
            "Прикладники (укр. Прикладники) — село, входит в Сенчицкии сельскии совет Заречненского раиона Ровненскои области Украины.\n",
            "Население по переписи 2001 года составляло 273 человека. Почтовыи индекс — 34012. Телефонныи код — 3632. Код КОАТУУ — 5622286203.\n",
            "ПРИКУРИВАТЕЛЬ\n",
            "Прикуриватель — устроиство, используемое для прикуривания сигарет во время езды в автомобиле, а гнездо прикуривателя также используется для подключения различных электроприборов к бортовои автомобильнои сети: в первую очередь, сам прикуриватель, автомобильныи компрессор, зарядное устроиство мобильного телефона.\n",
            "ПРИЛЕЖАНИЕ\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/wikipedia/wikipedia.py:389: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.6/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "DisambiguationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisambiguationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-df0b5c4a9655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HYPONYM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mget_hyperonyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-60-f5646b675834>\u001b[0m in \u001b[0;36mget_hyperonyms\u001b[0;34m(main_word)\u001b[0m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRULE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeaccent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\(.+?\\)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wikipedia/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(title, sentences, chars, auto_suggest, redirect)\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;31m# use auto_suggest and redirect to get the correct article\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m   \u001b[0;31m# also, use page's error checking to raise DisambiguationError if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m   \u001b[0mpage_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_suggest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_suggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m   \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mpageid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36mpage\u001b[0;34m(title, pageid, auto_suggest, redirect, preload)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m# if there is no suggestion or search results, the page doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mWikipediaPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mpageid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mWikipediaPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpageid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Either a title or a pageid must be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self, redirect, preload)\u001b[0m\n\u001b[1;32m    391\u001b[0m       \u001b[0mmay_refer_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mli\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_lis\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisambiguationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmay_refer_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisambiguationError\u001b[0m: \"приложение\" may refer to: \nкомпьютерная программа\nВеб-приложение\nПриложение (лингвистика)\nПриложение (СКС)\nOSI\nСервер приложений"
          ]
        }
      ]
    }
  ]
}