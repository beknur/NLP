{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BeknurSlamkul.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beknur/NLP/blob/master/BeknurSlamkul.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BsP8X727kQMe"
      },
      "source": [
        "<h3 style=\"text-align: center;\"><b>NLP Final Exam</b></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p-2rBvEkkQMj",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PHc7UePMkQMp"
      },
      "source": [
        "# Дисклеймер про CrossEntropyLoss и NLLLoss\n",
        "\n",
        "Обычно в PyTorch не нужно делать Softmax как последний слой модели. \n",
        "\n",
        "* Если Вы используете NLLLoss, то ему на вход надо давать лог вероятности, то есть выход слоя LogSoftmax. (Просто результат софтмакса, к которому применен логарифм)\n",
        "* Если Вы используете CrossEntropyLoss, то применение LogSoftmax уже включено внутрь лосса, поэтому ему на вход надо подавать просто выход обычного линейного слоя без активации. По сути CrossEntropyLoss = LogSoftmax + NLLLoss\n",
        "\n",
        "Зачем такие сложности, чтобы посчитать обычную кросс энтропию? Дело в том, что нам в любом случае придется взять логарифм от результатов софтмакса, а если делать это одной функцией, то можно сделать более устойчивую реализацию, которая даст меньшую вычислительную погрешность. \n",
        "\n",
        "Таким образом, если у вас в конце сети, решающей задачу классификации, стоит просто линейный слой без активации, то вам нужно использовать CrossEntropy. В notebook используется лосс CrossEntropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8rM9IY0YkQMq"
      },
      "source": [
        "# Задание 1. Создайте генератор батчей. \n",
        "\n",
        "В этот раз мы хотим сделать генератор, который будет максимально похож на то, что используется в реальном обучении. \n",
        "\n",
        "С помощью numpy вам нужно перемешать исходную выборку и выбирать из нее батчи размером batch_size, если размер выборки не делился на размер батча, то последний батч должен иметь размер меньше batch_size и состоять просто из всех оставшихся объектов. Возвращать нужно в формате (X_batch, y_batch). Необходимо написать именно генератор, то есть вместо return использовать yield. \n",
        "\n",
        "Хорошая статья про генераторы: https://habr.com/ru/post/132554/\n",
        "\n",
        "\n",
        "**Ответ на задание - код**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ttf6PZuVkQMr",
        "colab": {}
      },
      "source": [
        "def batch_generator(X, y, batch_size):\n",
        "    np.random.seed(42)\n",
        "    perm = np.random.permutation(len(X))\n",
        "\n",
        "    # YOUR CODE\n",
        "    for start in range(0, len(X), batch_size):\n",
        "        batch_idx = perm[start:start+batch_size]\n",
        "        yield X[batch_idx], y[batch_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2RvSIsl-c5lW"
      },
      "source": [
        "Попробуем потестировать наш код"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U_snYtUUcpDy",
        "colab": {}
      },
      "source": [
        "from inspect import isgeneratorfunction\n",
        "assert isgeneratorfunction(batch_generator), \"batch_generator должен быть генератором! В условии есть ссылка на доки\"\n",
        "\n",
        "X = np.array([\n",
        "              [1, 2, 3],\n",
        "              [4, 5, 6],\n",
        "              [7, 8, 9]\n",
        "])\n",
        "y = np.array([\n",
        "              1, 2, 3\n",
        "])\n",
        "\n",
        "# Проверим shape первого батча\n",
        "iterator = batch_generator(X, y, 2)\n",
        "X_batch, y_batch = next(iterator)\n",
        "assert X_batch.shape == (2, 3), y_batch.shape == (2,)\n",
        "assert np.allclose(X_batch, X[:2]), np.allclose(y_batch, y[:2])\n",
        "\n",
        "# Проверим shape последнего батча (их всего два)\n",
        "X_batch, y_batch = next(iterator)\n",
        "assert X_batch.shape == (1, 3), y_batch.shape == (1,)\n",
        "assert np.allclose(X_batch, X[2:]), np.allclose(y_batch, y[2:])\n",
        "\n",
        "# Проверим, что итерации закончились\n",
        "iter_ended = False\n",
        "try:\n",
        "    next(iterator)\n",
        "except StopIteration:\n",
        "    iter_ended = True\n",
        "assert iter_ended\n",
        "\n",
        "# Еще раз проверим то, сколько батчей создает итератор\n",
        "X = np.random.randint(0, 100, size=(1000, 100))\n",
        "y = np.random.randint(-1, 1, size=(1000, 1))\n",
        "num_iter = 0\n",
        "for _ in batch_generator(X, y, 3):\n",
        "    num_iter += 1\n",
        "assert num_iter == (1000 // 3 + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yJ9_3VfrkQMv"
      },
      "source": [
        "# Задание 2. Обучите модель для классификации звезд\n",
        "\n",
        "Загрузите датасет из файла sky_data.csv, разделите его на train/test и обучите на нем нейронную сеть (архитектура ниже). Обучайте на батчах с помощью оптимизатора Adam, lr подберите сами, пробуйте что-то вроде 1e-2\n",
        "\n",
        "Архитектура:\n",
        "\n",
        "1. Dense Layer с relu активацией и 50 нейронами\n",
        "2. Dropout 80% (если другой keep rate дает сходимость лучше, то можно изменить) (попробуйте 50%) \n",
        "3. BatchNorm\n",
        "4. Dense Layer с relu активацией и 100 нейронами\n",
        "5. Dropout 80% (если другой keep rate дает сходимость лучше, то можно изменить) (попробуйте для разнообразия 50%)\n",
        "6. BatchNorm\n",
        "7. Выходной Dense слой c количеством нейронов, равному количеству классов\n",
        "\n",
        "Лосс - CrossEntropy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qTd7VFMskQMw"
      },
      "source": [
        "В датасете классы представлены строками, поэтому классы нужно закодировать. Для этого в строчке ниже объявлен dict, с помощью него и функции map превратите столбец с таргетом в целое число. Кроме того, за вас мы выделили признаки, которые нужно использовать."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MTMs6bU6kQMx"
      },
      "source": [
        "### Загрузка и обработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ci8mdz99kQMy",
        "colab": {}
      },
      "source": [
        "feature_columns = ['ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'run', 'camcol', 'field']\n",
        "target_column = 'class'\n",
        "\n",
        "target_mapping = {\n",
        "    'GALAXY': 0,\n",
        "    'STAR': 1,\n",
        "    'QSO': 2\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QRcIYVvUkQM2",
        "outputId": "e1581327-4291-4267-a6fd-15b968754a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "data = pd.read_csv('https://drive.google.com/uc?id=1K-8CtATw6Sv7k2dXco1fL5MAhTbKtIH3')\n",
        "data['class'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GALAXY    4998\n",
              "STAR      4152\n",
              "QSO        850\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XQJyao1zoytL",
        "outputId": "2eb53078-2a07-4796-fe58-649e4d044700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>objid</th>\n",
              "      <th>ra</th>\n",
              "      <th>dec</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run</th>\n",
              "      <th>rerun</th>\n",
              "      <th>camcol</th>\n",
              "      <th>field</th>\n",
              "      <th>specobjid</th>\n",
              "      <th>class</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>mjd</th>\n",
              "      <th>fiberid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.237650e+18</td>\n",
              "      <td>183.531326</td>\n",
              "      <td>0.089693</td>\n",
              "      <td>19.47406</td>\n",
              "      <td>17.04240</td>\n",
              "      <td>15.94699</td>\n",
              "      <td>15.50342</td>\n",
              "      <td>15.22531</td>\n",
              "      <td>752</td>\n",
              "      <td>301</td>\n",
              "      <td>4</td>\n",
              "      <td>267</td>\n",
              "      <td>3.722360e+18</td>\n",
              "      <td>STAR</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>3306</td>\n",
              "      <td>54922</td>\n",
              "      <td>491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.237650e+18</td>\n",
              "      <td>183.598371</td>\n",
              "      <td>0.135285</td>\n",
              "      <td>18.66280</td>\n",
              "      <td>17.21449</td>\n",
              "      <td>16.67637</td>\n",
              "      <td>16.48922</td>\n",
              "      <td>16.39150</td>\n",
              "      <td>752</td>\n",
              "      <td>301</td>\n",
              "      <td>4</td>\n",
              "      <td>267</td>\n",
              "      <td>3.638140e+17</td>\n",
              "      <td>STAR</td>\n",
              "      <td>-0.000055</td>\n",
              "      <td>323</td>\n",
              "      <td>51615</td>\n",
              "      <td>541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.237650e+18</td>\n",
              "      <td>183.680207</td>\n",
              "      <td>0.126185</td>\n",
              "      <td>19.38298</td>\n",
              "      <td>18.19169</td>\n",
              "      <td>17.47428</td>\n",
              "      <td>17.08732</td>\n",
              "      <td>16.80125</td>\n",
              "      <td>752</td>\n",
              "      <td>301</td>\n",
              "      <td>4</td>\n",
              "      <td>268</td>\n",
              "      <td>3.232740e+17</td>\n",
              "      <td>GALAXY</td>\n",
              "      <td>0.123111</td>\n",
              "      <td>287</td>\n",
              "      <td>52023</td>\n",
              "      <td>513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.237650e+18</td>\n",
              "      <td>183.870529</td>\n",
              "      <td>0.049911</td>\n",
              "      <td>17.76536</td>\n",
              "      <td>16.60272</td>\n",
              "      <td>16.16116</td>\n",
              "      <td>15.98233</td>\n",
              "      <td>15.90438</td>\n",
              "      <td>752</td>\n",
              "      <td>301</td>\n",
              "      <td>4</td>\n",
              "      <td>269</td>\n",
              "      <td>3.722370e+18</td>\n",
              "      <td>STAR</td>\n",
              "      <td>-0.000111</td>\n",
              "      <td>3306</td>\n",
              "      <td>54922</td>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.237650e+18</td>\n",
              "      <td>183.883288</td>\n",
              "      <td>0.102557</td>\n",
              "      <td>17.55025</td>\n",
              "      <td>16.26342</td>\n",
              "      <td>16.43869</td>\n",
              "      <td>16.55492</td>\n",
              "      <td>16.61326</td>\n",
              "      <td>752</td>\n",
              "      <td>301</td>\n",
              "      <td>4</td>\n",
              "      <td>269</td>\n",
              "      <td>3.722370e+18</td>\n",
              "      <td>STAR</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>3306</td>\n",
              "      <td>54922</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          objid          ra       dec  ...  plate    mjd  fiberid\n",
              "0  1.237650e+18  183.531326  0.089693  ...   3306  54922      491\n",
              "1  1.237650e+18  183.598371  0.135285  ...    323  51615      541\n",
              "2  1.237650e+18  183.680207  0.126185  ...    287  52023      513\n",
              "3  1.237650e+18  183.870529  0.049911  ...   3306  54922      510\n",
              "4  1.237650e+18  183.883288  0.102557  ...   3306  54922      512\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "40-ivv77p9I2",
        "colab": {}
      },
      "source": [
        "# Extract Features\n",
        "X = data[feature_columns]\n",
        "# Extract target\n",
        "y = data[target_column]\n",
        "\n",
        "# encode target with target_mapping\n",
        "y.replace(target_mapping, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A3OkZT7HkQM7"
      },
      "source": [
        "Нормализация фичей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ynmXS7dMkQM8",
        "colab": {}
      },
      "source": [
        "# Просто вычтите среднее и поделитe на стандартное отклонение (с помощью пандас). Также преобразуйте всё в np.array\n",
        "X = ((X - np.mean(X))/np.std(X)).to_numpy()\n",
        "y = y.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WQ6EFNg4xhQ",
        "colab_type": "code",
        "outputId": "5008f4f6-f925-4cfd-f15c-3aecf0d5fb56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.16745842 -0.58492272  1.03148637 ... -0.83806089  0.21085172\n",
            "  -0.21763043]\n",
            " [ 0.16886159 -0.58311429  0.05243046 ... -0.83806089  0.21085172\n",
            "  -0.21763043]\n",
            " [ 0.17057433 -0.58347525  0.92156796 ... -0.83806089  0.21085172\n",
            "  -0.21147922]\n",
            " ...\n",
            " [-0.92039468  1.46090664  0.16753826 ...  1.33178452 -0.38935244\n",
            "  -0.86350751]\n",
            " [-0.92197294  1.46432109  0.31801835 ...  1.33178452 -0.38935244\n",
            "  -0.8573563 ]\n",
            " [-0.91804124  1.46639319  0.79229193 ...  1.33178452 -0.38935244\n",
            "  -0.8573563 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQLJwa2t40FS",
        "colab_type": "code",
        "outputId": "d41a026b-67fa-4541-cad0-129dfdcb23e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 0 ... 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XEIewITCqo38",
        "colab": {}
      },
      "source": [
        "assert type(X) == np.ndarray and type(y) == np.ndarray, 'Проверьте, что получившиеся массивы являются np.ndarray'\n",
        "assert np.allclose(y[:5], [1,1,0,1,1])\n",
        "assert X.shape == (10000, 10)\n",
        "assert np.allclose(X.mean(axis=0), np.zeros(10)) and np.allclose(X.std(axis=0), np.ones(10)), 'Данные не отнормированы'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VTcR3q0SkQNj"
      },
      "source": [
        "Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m5AFbCY4kQNk",
        "colab": {}
      },
      "source": [
        "# Split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "# Превратим данные в тензоры, чтобы потом было удобнее\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_test = torch.LongTensor(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZDCt0vtlkQNo"
      },
      "source": [
        "Хорошо, данные мы подготовили, теперь надо объявить модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fI6ZqCaCkQNp",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42) \n",
        "np.random.seed(42)\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(len(X[0]), 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.8),\n",
        "            nn.BatchNorm1d(50),\n",
        "            nn.Linear(50, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.8),\n",
        "            nn.BatchNorm1d(100),\n",
        "            nn.Linear(100, len(np.unique(y)))\n",
        "        )\n",
        "    \n",
        "loss_fn = torch.nn.SmoothL1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GkUkeHfokQNs"
      },
      "source": [
        "### Обучающий цикл"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "41jYcT6AkQNt",
        "colab": {}
      },
      "source": [
        "def train(X_train, y_train, X_test, y_test, num_epoch):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    for i in range(num_epoch):\n",
        "        epoch_train_losses = []\n",
        "        for X_batch, y_batch in batch_generator(X_train, y_train, 500):\n",
        "            # На лекции мы рассказывали, что дропаут работает по-разному во время обучения и реального предсказания\n",
        "            # Чтобы это учесть нам нужно включать и выключать режим обучения, делается это командой ниже\n",
        "            model.train(True)\n",
        "            # Посчитаем предсказание и лосс\n",
        "            # YOUR CODE\n",
        "            prediction = model(X_train)\n",
        "            loss = loss_fn(prediction, y_batch) \n",
        "            # зануляем градиент\n",
        "            # YOUR CODE\n",
        "            optimizer.zero_grad()\n",
        "            # backward\n",
        "            # YOUR CODE\n",
        "            loss.backward()\n",
        "            # ОБНОВЛЯЕМ веса\n",
        "            # YOUR CODE\n",
        "            optimizer.step()\n",
        "            # Запишем число (не тензор) в наши батчевые лоссы\n",
        "            epoch_train_losses.append(loss)        \n",
        "        train_losses.append(np.mean(epoch_train_losses))\n",
        "        \n",
        "        # Теперь посчитаем лосс на тесте\n",
        "        model.train(False)\n",
        "        with torch.no_grad():\n",
        "            # Сюда опять же надо положить именно число равное лоссу на всем тест датасете\n",
        "            test_losses.append(loss_fn(model(X_test), y_test))\n",
        "            \n",
        "    return train_losses, test_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "idGcIKlIth3D",
        "colab": {}
      },
      "source": [
        "def check_loss_decreased():\n",
        "    print(\"На графике сверху, точно есть сходимость? Точно-точно? [Да/Нет]\")\n",
        "    s = input()\n",
        "    if s.lower() == 'да':\n",
        "        print(\"Хорошо!\")\n",
        "    else:\n",
        "        raise RuntimeError(\"Можно уменьшить дропаут, уменьшить lr, поправить архитектуру, etc\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYISNzukE2jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cDyg5zMckQOX",
        "scrolled": false,
        "outputId": "1fe8de45-89b0-4b74-f592-106369f11b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "train_losses, test_losses = train(X_train, y_train, X_test, y_test, 1) #Подберите количество эпох так, чтобы график loss сходился\n",
        "#Тут застрял, и не сумел угадать num_epoch\n",
        "plt.plot(range(len(train_losses)), train_losses, label='train')\n",
        "plt.plot(range(len(test_losses)), test_losses, label='test')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "    \n",
        "check_loss_decreased()\n",
        "assert train_losses[-1] < 0.3 and test_losses[-1] < 0.3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:798: UserWarning: Using a target size (torch.Size([500])) that is different to the input size (torch.Size([7500, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.smooth_l1_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-241-85664cd323f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Подберите количество эпох так, чтобы график loss сходился\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#Тут застрял, и не сумел угадать num_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-235-9181a54c73be>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X_train, y_train, X_test, y_test, num_epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m# зануляем градиент\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msmooth_l1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2478\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (500) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UV1jaOM1SuTL"
      },
      "source": [
        "### Вычислите accuracy получившейся модели на train и test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dXqXflGcTBKS",
        "outputId": "df06eccf-d9d0-4d9d-c8bc-d85815ea782d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.eval()\n",
        "train_pred_labels = model(X_train)\n",
        "test_pred_labels = model(X_test)\n",
        "\n",
        "train_acc = accuracy_score(y_train, model(X_train))\n",
        "test_acc = accuracy_score(y_test, model(X_test))\n",
        "\n",
        "assert train_acc > 0.9, \"Если уж классифицировать звезды, которые уже видел, то не хуже, чем в 90% случаев\"\n",
        "assert test_acc > 0.9, \"Новые звезды тоже надо классифицировать хотя бы в 90% случаев\"\n",
        "\n",
        "print(\"Train accuracy: {}\\nTest accuracy: {}\".format(train_acc, test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-239-716dce1322f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_pred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be class 'SparseSeries' or 'SparseArray'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_multilabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'multilabel-indicator'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \"\"\"\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__array__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IB1XswA2kQOd"
      },
      "source": [
        "# Задание 3. Исправление ошибок в архитектуре\n",
        "\n",
        "Только что вы обучили полносвязную нейронную сеть. Теперь вам предстоит проанализировать архитектуру нейронной сети ниже, исправить в ней ошибки и  обучить её с помощью той же функции train. Пример исправления ошибок есть в семинаре Григория Лелейтнера.\n",
        "\n",
        "Будьте осторожнее и убедитесь, что перед запуском train вы вновь переопределили все необходимые внешние переменные (train обращается к глобальным переменным, в целом так делать не стоит, но сейчас это было оправдано, так как иначе нам пришлось бы передавать порядка 7-8 аргументов).\n",
        "\n",
        "Чтобы у вас получилась такая же архитектура, как у нас, и ответы совпали, давайте определим некоторые правила, как исправлять ошибки:\n",
        "\n",
        "1. Если вы видите лишний нелинейный слой, который стоит не на своем месте, просто удалите его. (не нужно добавлять новые слои, чтобы сделать постановку изначального слоя разумной. Удалять надо самый последний слой, который все портит. Для линейных слоев надо что-то исправить, а не удалить его)\n",
        "2. Если у слоя нет активации, то добавьте ReLU или другую подходящую активацию\n",
        "3. Если что-то не так с learning_rate, то поставьте 1e-2\n",
        "4. Если что-то не так с параметрами, считайте первый параметр, который появляется, как верный (т.е. далее в сети должен использоваться он).\n",
        "5. Ошибки могут быть и в полносвязных слоях. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Un7PyM39kQOe"
      },
      "source": [
        "Задача все та же - классификация небесных объектов на том же датасете. После исправления сети вам нужно обучить ее.\n",
        "\n",
        "**Ответ на задачу - средний лосс на тестовом датасете**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3M9P67WekQOe",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)   \n",
        "np.random.seed(42)\n",
        "# WRONG ARCH\n",
        "model = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(6, 50),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(100, 200),\n",
        "    nn.Softmax(),\n",
        "    nn.Linear(200, 200),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(200, 3),\n",
        "    nn.Dropout(p=0.5)\n",
        ")\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters[:-2], lr=1e-100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T0HEx6vbkQOi",
        "colab": {}
      },
      "source": [
        "# RIGHT ARCH\n",
        "torch.manual_seed(42)   \n",
        "np.random.seed(42)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(6, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.BatchNorm1d(100),\n",
        "            nn.Linear(100, 200),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.BatchNorm1d(50),\n",
        "            nn.Linear(200, 3)\n",
        ")\n",
        "\n",
        "\n",
        "loss_fn = torch.nn.SmoothL1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oGhmQg06gGiT"
      },
      "source": [
        "### Обучите и протестируйте модель так же, как вы это сделали в задаче 2. Вычислите accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7SZv9yARkQOo",
        "colab": {}
      },
      "source": [
        "#YOUR CODE\n",
        "\n",
        "train_acc = accuracy_score(y_train, model(X_train))\n",
        "test_acc = accuracy_score(y_test, model(X_test))\n",
        "\n",
        "\n",
        "assert train_acc > 0.9, \"Если уж классифицировать звезды, которые уже видел, то не хуже, чем в 90% случаев\"\n",
        "assert test_acc > 0.9, \"Новые звезды тоже надо классифицировать хотя бы в 90% случаев\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZoNWJVnY1wQ",
        "colab_type": "text"
      },
      "source": [
        "## Задание 4. Опишите в чем заключались ошибки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uajlTQeyItPt",
        "colab_type": "text"
      },
      "source": [
        "Dropout в начале не нужен"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "In4h-bM_g0Vb"
      },
      "source": [
        "## Задание 5. Опишите модель лематизации \n",
        "Необходимо описать пошагово на примере реализацию с помощью архитектуры Transformer состоящей из Encoder и Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBaiat4aKBKc",
        "colab_type": "text"
      },
      "source": [
        "Разница между стемминг (stemming) и лемматизацией заключается в том, что лемматизация учитывает контекст и преобразует слово в его значимую базовую форму, тогда как стемминг просто удаляет последние несколько символов, что часто приводит к неверному значению и орфографическим ошибкам.\n",
        "\n",
        "Например, лемматизация правильно определила бы базовую форму «caring» и «care», в то время как стемминг отрезал бы «ing» и преобразовал ее в car."
      ]
    }
  ]
}